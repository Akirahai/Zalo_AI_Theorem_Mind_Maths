{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:1')\n",
    "# torch.cuda.set_device(1)\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data:\n",
    "import json\n",
    "\n",
    "with open('data/eng_math_test.json') as f:\n",
    "    math_test = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing, add answer D to each question\n",
    "def Add_answer(data):\n",
    "    for i in range(len(data)):\n",
    "        exercise = data[i]\n",
    "        if len(exercise['choices']) < 4:\n",
    "            exercise['choices'].append('D. None of the above')\n",
    "Add_answer(math_test['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test_ds = Dataset.from_list(math_test['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model to run the predictions\n",
    "model_dir = \"model/Theorem_mind_bert_1\"\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = 'finetuned'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predictions_to_map_output(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    top_answer_indices = sorted_answer_indices[:,:1] \n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf680af1ee4101bcebb7a19ae0c525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the test_data\n",
    "options = 'ABCD'\n",
    "indices = list(range(4))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess_test(example):\n",
    "    first_sentence = [example['question']] * 4\n",
    "    second_sentence = []\n",
    "    for choice in example['choices']:\n",
    "        second_sentence.append(choice)\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n",
    "    tokenized_example['label'] = 0\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_test_ds = test_ds.map(preprocess_test, batched=False, remove_columns=['question','choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = trainer.predict(tokenized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_encode = predictions_to_map_output(test_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the second choice if the model choose D. None of the above\n",
    "def predictions_to_map_output_second_choice(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    top_answer_indices = sorted_answer_indices[:,1:2] \n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n",
    "\n",
    "\n",
    "for idx, question in enumerate(math_test['data']):\n",
    "    if question['choices'][3] == 'D. None of the above' and test_predictions_encode[idx] == 'D':\n",
    "        b = predictions_to_map_output_second_choice(test_predictions.predictions[idx:(idx+1)])\n",
    "        test_predictions_encode[idx] = b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/math_test.json') as f:\n",
    "    vi_math_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '01-0203',\n",
       " 'question': 'Một cửa hàng đã bán 30% số hàng hiện có và thu được 15 000 000 đồng. Hỏi nếu bán hết hàng thì cửa hàng thu được bao nhiêu tiền?',\n",
       " 'choices': ['A. 4 500 000 đồng',\n",
       "  'B. 45 000 000 đồng',\n",
       "  'C. 50 000 000 đồng',\n",
       "  'D. 450 000 000 đồng']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vi_math_test['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predicted_to_full_answers(test_data, predicted_answers):\n",
    "    full_answers = []\n",
    "\n",
    "    for item, predicted_label in zip(test_data, predicted_answers):\n",
    "        full_answer_text = next((text for label, text in zip([\"A\", \"B\", \"C\", \"D\"], item['choices']) if label == predicted_label), \"Unknown\")\n",
    "        full_answers.append((item['id'], full_answer_text))\n",
    "\n",
    "    return full_answers\n",
    "\n",
    "csv_data = map_predicted_to_full_answers(vi_math_test['data'], test_predictions_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01-0203', 'C. 50 000 000 đồng'),\n",
       " ('01-0206', 'A. 24 phút'),\n",
       " ('01-0207', 'C. 6 lần'),\n",
       " ('01-0209', 'C. 25%'),\n",
       " ('01-0210', 'C. 200m'),\n",
       " ('01-0211', 'C. 5,216'),\n",
       " ('01-0214', 'C. 21%'),\n",
       " ('01-0219', 'C. 8 giờ 17 phút'),\n",
       " ('01-0221', 'C. 0,75'),\n",
       " ('01-0222', 'C. 67,919'),\n",
       " ('01-0223', 'C. 30'),\n",
       " ('01-0224', 'C. 398,7'),\n",
       " ('01-0225', 'C. \\\\frac{7}{100}'),\n",
       " ('01-0227', 'C. 5 chục'),\n",
       " ('01-0232', 'A. 150%'),\n",
       " ('01-0234', 'C. \\\\frac{1}{2}'),\n",
       " ('01-0237', 'C. 350'),\n",
       " ('01-0239', 'C. 5019'),\n",
       " ('01-0240', 'C. 0,18 giờ'),\n",
       " ('01-0241', 'C. 369,92'),\n",
       " ('01-0243', 'C. 5 000'),\n",
       " ('01-0245', 'C. 37,4'),\n",
       " ('01-0246', 'C. 10,05'),\n",
       " ('01-0249', 'C. 3,005'),\n",
       " ('01-0254', 'C. 90 phút'),\n",
       " ('01-0256', 'C. 36 dm^{2}'),\n",
       " ('01-0257', 'C. 28,26 dm'),\n",
       " ('01-0258', 'C. 6,28 cm^{2}'),\n",
       " ('01-0259', 'C. 138 dm^{3}'),\n",
       " ('01-0264', 'C. 46%'),\n",
       " ('01-0266', 'C. 37,6'),\n",
       " ('01-0268', 'C. 201,700'),\n",
       " ('01-0269', 'C. 0,709'),\n",
       " ('01-0273', 'C. 30 phút'),\n",
       " ('01-0275', 'C. 4,3'),\n",
       " ('01-0277', 'C. 30 phút'),\n",
       " ('01-0285', 'C. 1234'),\n",
       " ('01-0292', 'C. 9 phút 36 giây'),\n",
       " ('01-0294', 'C. 348'),\n",
       " ('01-0296', 'C. 45 học sinh'),\n",
       " ('01-0302', 'C. \\\\frac{5}{4}'),\n",
       " ('01-0303', 'C. 8'),\n",
       " ('01-0305', 'C. 9 cm'),\n",
       " ('01-0314', 'C. 663,64'),\n",
       " ('01-0315', 'C. 8dm'),\n",
       " ('01-0316', 'C. 55,017'),\n",
       " ('01-0317', 'C. 40%'),\n",
       " ('01-0321', 'C. \\\\frac{9}{1000}'),\n",
       " ('01-0322', 'C. 480'),\n",
       " ('01-0324', 'C. 100 m^{3}'),\n",
       " ('01-0326', 'C. 6'),\n",
       " ('01-0329', 'C. 510 m/phút'),\n",
       " ('01-0330', 'C. 10 001'),\n",
       " ('01-0336', 'C. 30'),\n",
       " ('01-0337', 'C. 28,3'),\n",
       " ('01-0339', 'C. 0,2 tạ'),\n",
       " ('01-0340', 'C. 50,24 dm^{2}'),\n",
       " ('01-0343', 'C. 8dm'),\n",
       " ('01-0346', 'C. 55,702'),\n",
       " ('01-0347', 'C. 80%'),\n",
       " ('01-0351', 'C. 100'),\n",
       " ('01-0353', 'C. 55,017'),\n",
       " ('01-0358', 'C. 2 257'),\n",
       " ('01-0362', 'C. 3,5%'),\n",
       " ('01-0364', 'C. ='),\n",
       " ('01-0373', 'C. 0,023'),\n",
       " ('01-0375', 'C. 3046'),\n",
       " ('01-0376', 'C. 48 dm^{2}'),\n",
       " ('01-0378', 'C. 0,07'),\n",
       " ('01-0380', 'C. 417'),\n",
       " ('01-0384', 'C. 171,3'),\n",
       " ('01-0386', 'C. 453,0 m^{2}'),\n",
       " ('01-0387', 'C. 1527'),\n",
       " ('01-0389', 'C. Phần mười'),\n",
       " ('01-0390', 'C. 50 000'),\n",
       " ('01-0391', 'C. 150,07'),\n",
       " ('01-0394', 'C. 62,5%'),\n",
       " ('01-0397', 'C. 166'),\n",
       " ('01-0398', 'C. 2,3'),\n",
       " ('01-0401', 'C. 3,05 tấn'),\n",
       " ('01-0403', 'C. 1781,1'),\n",
       " ('01-0405', 'C. 9,08'),\n",
       " ('01-0407', 'C. 9 \\\\frac{6}{100}'),\n",
       " ('01-0409', 'C. 7 phần trăm'),\n",
       " ('01-0410', 'C. 4,6'),\n",
       " ('01-0412', 'C. 101,6'),\n",
       " ('01-0413', 'C. 9 chục'),\n",
       " ('01-0420', 'C. \\\\frac{5}{100}'),\n",
       " ('01-0422', 'C. 0,80'),\n",
       " ('01-0423', 'C. 11020 kg'),\n",
       " ('01-0425', 'C. 908'),\n",
       " ('01-0429', 'C. 8,60'),\n",
       " ('01-0431', 'C. 40,293'),\n",
       " ('01-0432', 'C. 5,5m^{2}'),\n",
       " ('01-0433', 'C. 0,3kg'),\n",
       " ('01-0434', 'C. 6,027 ha'),\n",
       " ('01-0435', 'C. 3,6m^{2}'),\n",
       " ('01-0437', 'C. 4,23; 5,3; 5,7; 6,02; 4,32'),\n",
       " ('01-0449', 'C. 35%'),\n",
       " ('01-0454', 'C. \\\\frac{35}{20}'),\n",
       " ('01-0456', 'C. 249'),\n",
       " ('01-0461', 'C. 0,05'),\n",
       " ('01-0463', 'C. 90cm^{2}'),\n",
       " ('01-0464', 'C. 1942,54'),\n",
       " ('01-0471', 'C. 3,04'),\n",
       " ('01-0472', 'C. 30000'),\n",
       " ('01-0474', 'C. 23 \\\\frac{5}{10}'),\n",
       " ('01-0476', 'C. 3,009'),\n",
       " ('01-0478', 'C. \\\\frac{11}{5}'),\n",
       " ('01-0480', 'C. 357,4'),\n",
       " ('01-0483', 'C. 6,732; 7; 7,009; 7,013'),\n",
       " ('01-0484', 'C. 83 000'),\n",
       " ('01-0486', 'C. 3,9'),\n",
       " ('01-0488', 'C. 240m^{2}'),\n",
       " ('01-0490', 'C. 5,002'),\n",
       " ('01-0492', 'C. 454,375'),\n",
       " ('01-0493', 'C. 356'),\n",
       " ('01-0498', 'C. 6,79'),\n",
       " ('01-0499', 'C. \\\\frac{27}{5}'),\n",
       " ('01-0500', 'C. Hàng phần trăm'),\n",
       " ('01-0502', 'C. 6,90'),\n",
       " ('01-0510', 'C. 64%'),\n",
       " ('01-0513', 'C. 0,01'),\n",
       " ('01-0518', 'C. 15 kg'),\n",
       " ('01-0519', 'C. 1,44 lần'),\n",
       " ('01-0525', 'C. 3'),\n",
       " ('01-0529', 'C. 40 ngày'),\n",
       " ('01-0536', 'C. 121,5 dm^{3}'),\n",
       " ('01-0538', 'C. 663,64'),\n",
       " ('01-0540', 'C. 55, 017'),\n",
       " ('01-0545', 'C. 30005'),\n",
       " ('01-0551', 'C. 115 giây'),\n",
       " ('01-0552', 'C. 16 cm^{2}'),\n",
       " ('01-0554', 'C. 6,28 cm'),\n",
       " ('01-0555', 'C. 0,32'),\n",
       " ('01-0556', 'C. 2000'),\n",
       " ('01-0561', 'C. 18,086'),\n",
       " ('01-0569', 'C. 4,210m^{3}'),\n",
       " ('01-0572', 'C. 450%'),\n",
       " ('01-0574', 'C. 66,7%'),\n",
       " ('01-0575', 'C. 3000 m^{2}'),\n",
       " ('01-0576', 'C. 45 km/giờ'),\n",
       " ('01-0578', 'C. 17 016'),\n",
       " ('01-0585', 'C. \\\\frac{5}{100}'),\n",
       " ('01-0589', 'C. 65,42'),\n",
       " ('01-0590', 'C. 1,7'),\n",
       " ('01-0591', 'C. 10,2'),\n",
       " ('01-0595', 'C. \\\\frac{8}{10}'),\n",
       " ('01-0597', 'C. 3600m^{2}'),\n",
       " ('01-0598', 'C. \\\\frac{6}{5}'),\n",
       " ('01-0604', 'C. 75%'),\n",
       " ('01-0605', 'C. 10'),\n",
       " ('01-0607', 'C. 14 hình tam giác'),\n",
       " ('01-0609', 'C. 6,90'),\n",
       " ('01-0611', 'C. 20,03'),\n",
       " ('01-0614', 'C. 37,5'),\n",
       " ('01-0616', 'C. 32%'),\n",
       " ('01-0617', 'C. 153cm^{2}'),\n",
       " ('01-0622', 'C. 7'),\n",
       " ('01-0625', 'C. 34,6'),\n",
       " ('01-0626', 'C. 9,952'),\n",
       " ('01-0630', 'C. 8,25'),\n",
       " ('01-0631', 'C. 110m^{2}'),\n",
       " ('01-0637', 'C. 0,001'),\n",
       " ('01-0640', 'C. 8750'),\n",
       " ('01-0642', 'C. \\\\frac{18}{15}'),\n",
       " ('01-0643', 'C. 1,03'),\n",
       " ('01-0644', 'C. 0,80'),\n",
       " ('01-0645', 'C. 4,32'),\n",
       " ('01-0649', 'C. 85%'),\n",
       " ('01-0650', 'C. 6400 đồng'),\n",
       " ('01-0652', 'C. 2301'),\n",
       " ('01-0653', 'C. 69,01'),\n",
       " ('01-0661', 'C. 144 giờ'),\n",
       " ('01-0663', 'C. 600'),\n",
       " ('01-0667', 'C. 2 km'),\n",
       " ('01-0670', 'C. 100'),\n",
       " ('01-0672', 'C. 55, 017'),\n",
       " ('01-0678', 'C. \\\\frac{8}{10}'),\n",
       " ('01-0683', 'C. 120,5'),\n",
       " ('01-0687', 'C. \\\\frac{9}{100}'),\n",
       " ('01-0690', 'C. 68,7'),\n",
       " ('01-0691', 'C. 50,798'),\n",
       " ('01-0694', 'C. 24%'),\n",
       " ('01-0698', 'C. 45,1'),\n",
       " ('01-0703', 'C. 3,75 %'),\n",
       " ('01-0715', 'C. 456,2'),\n",
       " ('01-0716', 'C. 3,05'),\n",
       " ('01-0717', 'C. 185 dm^{2}')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_answers_to_csv(data, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',', quotechar='', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "        csvwriter.writerow(['id', 'answer'])\n",
    "\n",
    "        for row in data:\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "write_answers_to_csv(csv_data, \"results/submission_bert_7.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_cuda1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
