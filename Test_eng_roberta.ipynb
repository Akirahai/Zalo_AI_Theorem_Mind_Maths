{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device('cuda:1')\n",
    "# torch.cuda.set_device(1)\n",
    "# torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data:\n",
    "import json\n",
    "\n",
    "with open('data/eng_math_test.json') as f:\n",
    "    math_test = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing, add answer D to each question\n",
    "def Add_answer(data):\n",
    "    for i in range(len(data)):\n",
    "        exercise = data[i]\n",
    "        if len(exercise['choices']) < 4:\n",
    "            exercise['choices'].append('D. None of the above')\n",
    "Add_answer(math_test['data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "test_ds = Dataset.from_list(math_test['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model to run the predictions\n",
    "model_dir = \"model/Theorem_mind_roberta\"\n",
    "from transformers import AutoTokenizer, RobertaForMultipleChoice\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = RobertaForMultipleChoice.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
    "from typing import Optional, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForMultipleChoice:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    \n",
    "    def __call__(self, features):\n",
    "        label_name = \"label\" if 'label' in features[0].keys() else 'labels'\n",
    "        labels = [feature.pop(label_name) for feature in features]\n",
    "        batch_size = len(features)\n",
    "        num_choices = len(features[0]['input_ids'])\n",
    "        flattened_features = [\n",
    "            [{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features\n",
    "        ]\n",
    "        flattened_features = sum(flattened_features, [])\n",
    "        \n",
    "        batch = self.tokenizer.pad(\n",
    "            flattened_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
    "        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model_dir = 'finetuned'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=50,\n",
    "    weight_decay=0.01,\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def predictions_to_map_output(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    top_answer_indices = sorted_answer_indices[:,:1] \n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002d4832d4254a42a8011d206e22e3df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/189 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the test_data\n",
    "options = 'ABCD'\n",
    "indices = list(range(4))\n",
    "\n",
    "option_to_index = {option: index for option, index in zip(options, indices)}\n",
    "index_to_option = {index: option for option, index in zip(options, indices)}\n",
    "\n",
    "def preprocess_test(example):\n",
    "    first_sentence = [example['question']] * 4\n",
    "    second_sentence = []\n",
    "    for choice in example['choices']:\n",
    "        second_sentence.append(choice)\n",
    "    tokenized_example = tokenizer(first_sentence, second_sentence, truncation=True)\n",
    "    tokenized_example['label'] = 0\n",
    "    return tokenized_example\n",
    "\n",
    "tokenized_test_ds = test_ds.map(preprocess_test, batched=False, remove_columns=['question','choices'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6/16 00:00 < 00:00, 28.25 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_predictions = trainer.predict(tokenized_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_encode = predictions_to_map_output(test_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the second choice if the model choose D. None of the above\n",
    "def predictions_to_map_output_second_choice(predictions):\n",
    "    sorted_answer_indices = np.argsort(-predictions)\n",
    "    top_answer_indices = sorted_answer_indices[:,1:2] \n",
    "    top_answers = np.vectorize(index_to_option.get)(top_answer_indices)\n",
    "    return np.apply_along_axis(lambda row: ' '.join(row), 1, top_answers)\n",
    "\n",
    "\n",
    "for idx, question in enumerate(math_test['data']):\n",
    "    if question['choices'][3] == 'D. None of the above' and test_predictions_encode[idx] == 'D':\n",
    "        b = predictions_to_map_output_second_choice(test_predictions.predictions[idx:(idx+1)])\n",
    "        test_predictions_encode[idx] = b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/math_test.json') as f:\n",
    "    vi_math_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predicted_to_full_answers(test_data, predicted_answers):\n",
    "    full_answers = []\n",
    "\n",
    "    for item, predicted_label in zip(test_data, predicted_answers):\n",
    "        full_answer_text = next((text for label, text in zip([\"A\", \"B\", \"C\", \"D\"], item['choices']) if label == predicted_label), \"Unknown\")\n",
    "        full_answers.append((item['id'], full_answer_text))\n",
    "\n",
    "    return full_answers\n",
    "\n",
    "csv_data = map_predicted_to_full_answers(vi_math_test['data'], test_predictions_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01-0203', 'D. 450 000 000 đồng'),\n",
       " ('01-0206', 'B. 1 giờ'),\n",
       " ('01-0207', 'B. 4 lần'),\n",
       " ('01-0209', 'B. 20%'),\n",
       " ('01-0210', 'C. 200m'),\n",
       " ('01-0211', 'B. 5,621'),\n",
       " ('01-0214', 'D. 49%'),\n",
       " ('01-0219', 'A. 7 giờ 17 phút'),\n",
       " ('01-0221', 'A. 75'),\n",
       " ('01-0222', 'D. 6,7919'),\n",
       " ('01-0223', 'A. 80'),\n",
       " ('01-0224', 'C. 398,7'),\n",
       " ('01-0225', 'D. \\\\frac{7}{1000}'),\n",
       " ('01-0227', 'B. 5 phần trăm'),\n",
       " ('01-0232', 'C. 1500%'),\n",
       " ('01-0234', 'B. \\\\frac{1}{4}'),\n",
       " ('01-0237', 'D. 1250'),\n",
       " ('01-0239', 'D. 5190'),\n",
       " ('01-0240', 'A. 0,02 giờ'),\n",
       " ('01-0241', 'C. 369,92'),\n",
       " ('01-0243', 'D. 50 000 000'),\n",
       " ('01-0245', 'C. 37,4'),\n",
       " ('01-0246', 'C. 10,05'),\n",
       " ('01-0249', 'D. 3,05'),\n",
       " ('01-0254', 'A. 1 giờ 2 phút'),\n",
       " ('01-0256', 'C. 36 dm^{2}'),\n",
       " ('01-0257', 'C. 28,26 dm'),\n",
       " ('01-0258', 'B. 5.14 cm^{2}'),\n",
       " ('01-0259', 'B. 13800 dm^{3}'),\n",
       " ('01-0264', 'C. 46%'),\n",
       " ('01-0266', 'D. 3,076'),\n",
       " ('01-0268', 'D. 201,07'),\n",
       " ('01-0269', 'C. 0,709'),\n",
       " ('01-0273', 'A. 10 phút'),\n",
       " ('01-0275', 'C. 4,3'),\n",
       " ('01-0277', 'A. 10 phút'),\n",
       " ('01-0285', 'A. 0,1234'),\n",
       " ('01-0292', 'A. 1 phút 12 giây'),\n",
       " ('01-0294', 'D. 3048'),\n",
       " ('01-0296', 'C. 45 học sinh'),\n",
       " ('01-0302', 'C. \\\\frac{5}{4}'),\n",
       " ('01-0303', 'A. 0,008'),\n",
       " ('01-0305', 'D. 81 cm'),\n",
       " ('01-0314', 'A. 70,765'),\n",
       " ('01-0315', 'B. 4dm'),\n",
       " ('01-0316', 'D. 55,000017'),\n",
       " ('01-0317', 'C. 40%'),\n",
       " ('01-0321', 'D. \\\\frac{9}{10000}'),\n",
       " ('01-0322', 'C. 480'),\n",
       " ('01-0324', 'B. 125 m^{3}'),\n",
       " ('01-0326', 'B. 0,6'),\n",
       " ('01-0329', 'B. 805 m/phút'),\n",
       " ('01-0330', 'B. 10 000'),\n",
       " ('01-0336', 'A. 10'),\n",
       " ('01-0337', 'B. 3,82'),\n",
       " ('01-0339', 'B. 0,02 tạ'),\n",
       " ('01-0340', 'B. 502,4 dm^{2}'),\n",
       " ('01-0343', 'B. 4dm'),\n",
       " ('01-0346', 'B. 55,072'),\n",
       " ('01-0347', 'D. 85%'),\n",
       " ('01-0351', 'D. 105,5'),\n",
       " ('01-0353', 'D. 55,000017'),\n",
       " ('01-0358', 'B. 2,257'),\n",
       " ('01-0362', 'B. 50%'),\n",
       " ('01-0364', 'A. <'),\n",
       " ('01-0373', 'D. 0,0023'),\n",
       " ('01-0375', 'A. 34600'),\n",
       " ('01-0376', 'C. 48 dm^{2}'),\n",
       " ('01-0378', 'C. 0,07'),\n",
       " ('01-0380', 'C. 417'),\n",
       " ('01-0384', 'C. 171,3'),\n",
       " ('01-0386', 'B. 453 m^{2}'),\n",
       " ('01-0387', 'A. 15,274'),\n",
       " ('01-0389', 'A. Chục'),\n",
       " ('01-0390', 'C. 50 000'),\n",
       " ('01-0391', 'B. 151,07'),\n",
       " ('01-0394', 'A. 37,5%'),\n",
       " ('01-0397', 'D. 2,06'),\n",
       " ('01-0398', 'D. 2,06'),\n",
       " ('01-0401', 'D. 3,005 tấn'),\n",
       " ('01-0403', 'B. 3821,2'),\n",
       " ('01-0405', 'B. 9,80'),\n",
       " ('01-0407', 'B. 6 \\\\frac{9}{10}'),\n",
       " ('01-0409', 'C. 7 phần trăm'),\n",
       " ('01-0410', 'A. 4,35'),\n",
       " ('01-0412', 'B. 106.6'),\n",
       " ('01-0413', 'C. 9 chục'),\n",
       " ('01-0420', 'C. \\\\frac{5}{100}'),\n",
       " ('01-0422', 'D. 0,080'),\n",
       " ('01-0423', 'B. 1102 kg'),\n",
       " ('01-0425', 'B. 980'),\n",
       " ('01-0429', 'B. 0,806'),\n",
       " ('01-0431', 'B. 39,204'),\n",
       " ('01-0432', 'A. 75m^{2}'),\n",
       " ('01-0433', 'B. 0,03 kg'),\n",
       " ('01-0434', 'B. 0,0627 ha'),\n",
       " ('01-0435', 'D. 54m^{2}'),\n",
       " ('01-0437', 'A. 5,7; 6,02; 4,23; 4,32; 5,3'),\n",
       " ('01-0449', 'A. 75%'),\n",
       " ('01-0454', 'A. \\\\frac{27}{10}'),\n",
       " ('01-0456', 'B. 2490'),\n",
       " ('01-0461', 'A. 0,005'),\n",
       " ('01-0463', 'A. 900cm^{2}'),\n",
       " ('01-0464', 'C. 1942,54'),\n",
       " ('01-0471', 'D. 3,004'),\n",
       " ('01-0472', 'C. 30000'),\n",
       " ('01-0474', 'B. 2 \\\\frac{35}{100}'),\n",
       " ('01-0476', 'C. 3,009'),\n",
       " ('01-0478', 'D. \\\\frac{17}{5}'),\n",
       " ('01-0480', 'B. 375,4'),\n",
       " ('01-0483', 'B. 5,494; 5,493; 5,392; 5,001'),\n",
       " ('01-0484', 'C. 83 000'),\n",
       " ('01-0486', 'B. 3,09'),\n",
       " ('01-0488', 'B. 204m'),\n",
       " ('01-0490', 'B. 5,02'),\n",
       " ('01-0492', 'A. 4,54375'),\n",
       " ('01-0493', 'A. 35,06'),\n",
       " ('01-0498', 'B. 7,99'),\n",
       " ('01-0499', 'D. \\\\frac{17}{5}'),\n",
       " ('01-0500', 'D. Hàng phần mười'),\n",
       " ('01-0502', 'B. 20,70'),\n",
       " ('01-0510', 'C. 64%'),\n",
       " ('01-0513', 'B. 0,1'),\n",
       " ('01-0518', 'B. 13 kg'),\n",
       " ('01-0519', 'B. 2,24 lần'),\n",
       " ('01-0525', 'B. 1,5'),\n",
       " ('01-0529', 'A. 10 ngày'),\n",
       " ('01-0536', 'D. 729 dm^{3}'),\n",
       " ('01-0538', 'A. 70,765'),\n",
       " ('01-0540', 'D. 55, 000017'),\n",
       " ('01-0545', 'B. 3005'),\n",
       " ('01-0551', 'C. 115 giây'),\n",
       " ('01-0552', 'C. 16 cm^{2}'),\n",
       " ('01-0554', 'A. 3,14 cm^{2}'),\n",
       " ('01-0555', 'C. 0,32'),\n",
       " ('01-0556', 'D. 20 000'),\n",
       " ('01-0561', 'C. 18,086'),\n",
       " ('01-0569', 'B. 4,021 m^{3}'),\n",
       " ('01-0572', 'A. 45%'),\n",
       " ('01-0574', 'D. 150%'),\n",
       " ('01-0575', 'C. 3000 m^{2}'),\n",
       " ('01-0576', 'B. 40 km/giờ'),\n",
       " ('01-0578', 'D. 170 016'),\n",
       " ('01-0585', 'B. \\\\frac{5}{100}'),\n",
       " ('01-0589', 'A. 62,54'),\n",
       " ('01-0590', 'A. 10,7'),\n",
       " ('01-0591', 'C. 10,2'),\n",
       " ('01-0595', 'D. \\\\frac{8}{10000}'),\n",
       " ('01-0597', 'C. 3600m^{2}'),\n",
       " ('01-0598', 'C. \\\\frac{6}{5}'),\n",
       " ('01-0604', 'B. 0,75%'),\n",
       " ('01-0605', 'D. 0,1'),\n",
       " ('01-0607', 'D. 15 hình tam giác'),\n",
       " ('01-0609', 'B. 20,70'),\n",
       " ('01-0611', 'B. 2,0003'),\n",
       " ('01-0614', 'D. 375'),\n",
       " ('01-0616', 'C. 32%'),\n",
       " ('01-0617', 'C. 153cm^{2}'),\n",
       " ('01-0622', 'D. \\\\frac{7}{1000}'),\n",
       " ('01-0625', 'D. 34,006'),\n",
       " ('01-0626', 'D. 9,95'),\n",
       " ('01-0630', 'B. 7,54'),\n",
       " ('01-0631', 'B. 447m^{2}'),\n",
       " ('01-0637', 'D. 0,0001'),\n",
       " ('01-0640', 'C. 8750'),\n",
       " ('01-0642', 'D. \\\\frac{24}{15}'),\n",
       " ('01-0643', 'A. 1 \\\\frac{3}{1000}'),\n",
       " ('01-0644', 'B. 0,080'),\n",
       " ('01-0645', 'C. 4,32'),\n",
       " ('01-0649', 'D. 19%'),\n",
       " ('01-0650', 'B. 36000 đồng'),\n",
       " ('01-0652', 'D. 200301'),\n",
       " ('01-0653', 'B. 70,01'),\n",
       " ('01-0661', 'A. 154 giờ'),\n",
       " ('01-0663', 'C. 600'),\n",
       " ('01-0667', 'B. 4 km'),\n",
       " ('01-0670', 'C. 100'),\n",
       " ('01-0672', 'D. 55, 000017'),\n",
       " ('01-0678', 'C. \\\\frac{8}{10}'),\n",
       " ('01-0683', 'B. 12,05'),\n",
       " ('01-0687', 'D. \\\\frac{9}{1000}'),\n",
       " ('01-0690', 'B. 68,007'),\n",
       " ('01-0691', 'B. 50,789'),\n",
       " ('01-0694', 'D. 100%'),\n",
       " ('01-0698', 'A. 451'),\n",
       " ('01-0703', 'D. 0,375 %'),\n",
       " ('01-0715', 'D. 4562'),\n",
       " ('01-0716', 'B. 3,04'),\n",
       " ('01-0717', 'C. 185 dm^{2}')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_answers_to_csv(data, filename):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=',', quotechar='', quoting=csv.QUOTE_NONE, escapechar='\\\\')\n",
    "        csvwriter.writerow(['id', 'answer'])\n",
    "\n",
    "        for row in data:\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "write_answers_to_csv(csv_data, \"results/submission_roberta_6.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_cuda1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
